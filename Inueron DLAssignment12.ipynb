{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e1277d8",
   "metadata": {},
   "source": [
    " 1. How does unsqueeze help us to solve certain broadcasting problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e930a30",
   "metadata": {},
   "source": [
    "Returns a new tensor with a dimension of size one inserted at the specified position. The returned tensor shares the same underlying data with this tensor. A dim value within the range [-input.dim() - 1, input.dim() + 1) can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c5f2cf",
   "metadata": {},
   "source": [
    "2.\tWhat do ou mean by underfitting in neural networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5bb21",
   "metadata": {},
   "source": [
    "When a model has not learned the patterns in the training data well and is unable to generalize well on the new data, it is known as underfitting. An underfit model has poor performance on the training data and will result in unreliable predictions. Underfitting occurs due to high bias and low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a30c3c",
   "metadata": {},
   "source": [
    "3.\tHow do we show the actual contents of the memory used for a tensor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094c3e3b",
   "metadata": {},
   "source": [
    "For each tensor, you have a method element_size() that will give you the size of one element in byte. And a function nelement() that returns the number of elements. So the size of a tensor a in memory (cpu memory for a cpu tensor and gpu memory for a gpu tensor) is a. element_size() * a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d090fb",
   "metadata": {},
   "source": [
    "4.\tDo broadcasting and expand_as result in increased memory use? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53939b9d",
   "metadata": {},
   "source": [
    "expand() will never allocate new memory. And so require the expanded dimension to be of size 1. repeat() will always allocate new memory and the repeated dimension can be of any size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ad1932",
   "metadata": {},
   "source": [
    "5.\tWhat are the forward pass and backward pass of a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec2f25d",
   "metadata": {},
   "source": [
    "Forward Propagation is the way to move from the Input layer (left) to the Output layer (right) in the neural network. The process of moving from the right to left i.e backward from the Output to the Input layer is called the Backward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95c6771",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55431034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
